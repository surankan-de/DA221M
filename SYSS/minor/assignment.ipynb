{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
    "df2 = pd.read_csv(\"tmdb_5000_movies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = df2\n",
    "main_df['cast'] = df1[\"cast\"]\n",
    "main_df['crew'] = df1['crew']\n",
    "main_df = main_df[[\"overview\",\"popularity\",\"title\",\"vote_average\",\"vote_count\",\"cast\",\"crew\",\"keywords\",\"genres\"]]\n",
    "main_df.fillna(\" \",inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodf = main_df[main_df[\"vote_count\"]>main_df['vote_count'].quantile(0.95)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##weighted rating formula\n",
    "def weighted_rating(df):\n",
    "    v=df['vote_count']\n",
    "    m=main_df['vote_count'].quantile(q=0.95)\n",
    "    r=df['vote_average']\n",
    "    c=main_df['vote_average'].mean()\n",
    "    wr = (r*v+c*m)/(v+m)\n",
    "    return wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodf[\"weighted_rating\"] = demodf.apply(weighted_rating,axis =1)\n",
    "## scaling popularity to same range\n",
    "demodf[\"popularity\"] = 10*(demodf[\"popularity\"]/max(demodf[\"popularity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_by_wr(n):\n",
    "    dft = demodf.sort_values(by = 'weighted_rating',ascending = False).head(min(n,len(demodf)))\n",
    "    toshow = list(dft['title'])\n",
    "    for i in range(len(toshow)):\n",
    "        print(i+1,toshow[i])\n",
    "\n",
    "def show_by_wr_and_pop(n):\n",
    "    demodf1 = demodf\n",
    "    demodf1[\"sums\"] = demodf[\"popularity\"]+demodf[\"weighted_rating\"]\n",
    "    dft = demodf1.sort_values(by = 'sums',ascending = False).head(min(n,len(demodf)))\n",
    "    toshow = list(dft['title'])\n",
    "    for i in range(len(toshow)):\n",
    "        print(i+1,toshow[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_vect = TfidfVectorizer(stop_words =\"english\") ##to remove words like and the etc\n",
    "tf_matrix = tf_vect.fit_transform(main_df['overview'])\n",
    "\n",
    "similarities = cosine_similarity(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {} ## to keep track of the indexes\n",
    "for i in range(len(main_df['title'])):\n",
    "    titl = main_df['title'][i]\n",
    "    keys[titl.lower().replace(' ','')] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def contentbasedreco(title,n):\n",
    "    idx = keys[title.lower().replace(' ','')]\n",
    "    check = list(enumerate(similarities[idx]))\n",
    "    check.sort(key = lambda x:x[1],reverse = True)\n",
    "    print(\"the movie recommendations according to the title searched are:\")\n",
    "    for i in range(1,min(n+1,len(check)),1):\n",
    "        print(i,main_df.iloc[check[i][0]]['title'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ['cast' ,\"crew\",\"keywords\",\"genres\"]\n",
    "for col in new:\n",
    "    main_df[col] = main_df[col].apply(json.loads)\n",
    "\n",
    "\n",
    "## functions for crew mebers fetch and normal name check\n",
    "def director(x):\n",
    "    for a in x:\n",
    "        if a['job']=='Director':\n",
    "            return a['name'].lower().replace(' ','')\n",
    "    return 'NaN'.lower().replace(' ','')\n",
    "\n",
    "def somecrew(x):\n",
    "    new=[]\n",
    "    for a in x[:min(5,len(x))]:\n",
    "        new.append(a['name'].lower().replace(' ','')) \n",
    "    return new\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "main_df['director']=main_df['crew'].apply(lambda x: director(x))\n",
    "main_df['actor']=main_df['cast'].apply(lambda x:somecrew(x))\n",
    "main_df['genres']=main_df['genres'].apply(lambda x:somecrew(x))\n",
    "main_df['keywords']=main_df['keywords'].apply(lambda x:somecrew(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['actor']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "\n",
    "main_df['meta'] = main_df.apply(metadata, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix_2 = tf_vect.fit_transform(main_df['meta'])\n",
    "similarities_2 = cosine_similarity(tf_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crewbasedreco(title,n):\n",
    "    idx = keys[title.lower().replace(' ','')]\n",
    "    check = list(enumerate(similarities_2[idx]))\n",
    "    check.sort(key = lambda x:x[1],reverse = True)\n",
    "    print(\"the movie recommendations according to the related crews,casts are:\")\n",
    "    for i in range(1,min(n+1,len(check)),1):\n",
    "        print(i,main_df.iloc[check[i][0]]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overallreco(title,n):\n",
    "    if(title==\"-1\"):\n",
    "        print(\"according to ratings\")\n",
    "        show_by_wr(n)\n",
    "        print(\" \")\n",
    "        print(\"according to both ratings and popularity\")\n",
    "        show_by_wr_and_pop(n)\n",
    "    else:\n",
    "        try:\n",
    "            contentbasedreco(title,n)           \n",
    "            crewbasedreco(title,n)\n",
    "        except Exception as e:\n",
    "            print(\"not much movies related to this movie! try something else\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colldf = pd.read_csv(\"ratings_small.csv\")\n",
    "colldf.head()\n",
    "ar = colldf['movieId'].value_counts().index\n",
    "di = {}\n",
    "ide = {}\n",
    "for i in range(len(ar)):\n",
    "    di[ar[i]] = i+1\n",
    "    ide[i+1] = ar[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(colldf['movieId'])):\n",
    "    if(i%10000==0):\n",
    "        print(i)\n",
    "    colldf['movieId'][i] = di[colldf['movieId'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_m = np.ndarray(shape = (np.max(colldf['movieId'].values),np.max(colldf['userId'])))\n",
    "r_m[colldf['movieId'].values-1,colldf['userId'].values-1] = colldf['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_m = r_m - np.asarray([np.mean(r_m,1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,v = np.linalg.svd(r_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf = pd.read_csv(\"links_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collabreco(movie_id,n):\n",
    "    rm = v.T[:,:50]\n",
    "    dt = rm[movie_id-1,:]\n",
    "    \n",
    "    sim = np.dot(dt,rm.T)\n",
    "    idxs = np.argsort(-sim)\n",
    "    print(\"some movies that are liked by fans of this movie are\")\n",
    "    i =0\n",
    "    for idx in idxs[:min(n,len(idxs))]:\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            chidx = ide[idx]\n",
    "            dfidx = checkdf[checkdf.movieId==chidx].tmdbId.values[0]\n",
    "            print(i+1,df1[df1.movie_id==dfidx].title.values[0])\n",
    "            i =i +1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie_name,n):\n",
    "    try:\n",
    "        overallreco(movie_name,n)\n",
    "    except Exception as e:\n",
    "        print(\"not much data about the movie\")\n",
    "    try:\n",
    "        id1 = keys[movie_name.lower().replace(' ','')]\n",
    "        id2 = df1.iloc[id1]['movie_id']\n",
    "        id3 = checkdf[checkdf.tmdbId==id2].movieId.values[0]\n",
    "        id4 = di[id3]\n",
    "        collabreco(id4,n)\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the movie recommendations according to the title searched are:\n",
      "1 Civil Brand\n",
      "2 Prison\n",
      "the movie recommendations according to the related crews,casts are:\n",
      "1 Catch a Fire\n",
      "2 The Hudsucker Proxy\n",
      "some movies that are liked by fans of this movie are\n",
      "1 Dumb and Dumber\n",
      "2 Big\n"
     ]
    }
   ],
   "source": [
    "recommend(\"the shawshank redemption\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8891  0.8928  0.8971  0.8981  0.9102  0.8975  0.0071  \n",
      "MAE (testset)     0.6855  0.6885  0.6938  0.6916  0.7000  0.6919  0.0050  \n",
      "Fit time          1.01    1.14    0.90    0.92    1.01    0.99    0.08    \n",
      "Test time         0.12    0.09    0.19    0.11    0.12    0.13    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.88913321, 0.89277222, 0.89709493, 0.89806644, 0.91023508]),\n",
       " 'test_mae': array([0.68546352, 0.68846075, 0.69378735, 0.6915959 , 0.7000305 ]),\n",
       " 'fit_time': (1.0077953338623047,\n",
       "  1.1374835968017578,\n",
       "  0.8998796939849854,\n",
       "  0.9151120185852051,\n",
       "  1.0079929828643799),\n",
       " 'test_time': (0.11514139175415039,\n",
       "  0.09123444557189941,\n",
       "  0.18954753875732422,\n",
       "  0.10870146751403809,\n",
       "  0.12476491928100586)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##code taken from surprise documentation for performance measures\n",
    "from surprise import Dataset, SVD, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(colldf[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
